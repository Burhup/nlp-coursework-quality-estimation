{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omEQHVdOS61G"
   },
   "source": [
    "# NLP Coursework - LASER Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lweXud1Wpemd"
   },
   "source": [
    "## Import data and transform to LASER embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93503236]]\n"
     ]
    }
   ],
   "source": [
    "# Test if LASER service is working\n",
    "def get_vect(query_in, lang = 'en', address = '127.0.0.1:8050'):\n",
    "    url = \"http://\" + address + \"/vectorize\"\n",
    "    params = {\"q\": query_in, \"lang\": lang}\n",
    "    resp = requests.get(url=url, params=params).json()\n",
    "    return resp[\"embedding\"]\n",
    "\n",
    "# Test to get vector embeddings\n",
    "input_dict = {\n",
    "    \"en\":\"Machine learning isn't as hard as people think.\",\n",
    "    \"de\":\"Maschinelles Lernen ist nicht so schwer wie die Leute denken.\",\n",
    "}\n",
    "\n",
    "embedded_dict = {}\n",
    "for key in input_dict:\n",
    "    embedded_dict[key] = np.array(get_vect(input_dict[key], lang = key))\n",
    "    \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_lib = cosine_similarity(embedded_dict['de'], embedded_dict['en'])\n",
    "\n",
    "print(cos_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation data\n",
    "f_train_scores = open(\"./train.ende.scores\",'r')\n",
    "de_train_scores = f_train_scores.readlines()\n",
    "\n",
    "f_train_scores_VAL = open(\"./dev.ende.scores\",'r')\n",
    "de_train_scores_VAL = f_train_scores_VAL.readlines()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/group-59/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "#downloading stopwords from the nltk package\n",
    "download('stopwords') #stopwords dictionary, run once\n",
    "\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_de = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LASER vectors for training\n",
    "file_de = open(\"./train.ende.src\") \n",
    "file_en = open(\"./train.ende.mt\") \n",
    "\n",
    "file_de_VAL = open(\"./dev.ende.src\") \n",
    "file_en_VAL = open(\"./dev.ende.mt\") \n",
    "\n",
    "files = [{\"name\": \"training_LASER_embeddings\", \"file_de\": file_de, \"file_en\": file_en},\n",
    "         {\"name\": \"validation_LASER_embeddings\", \"file_de\": file_de_VAL, \"file_en\": file_en_VAL}]\n",
    "\n",
    "for file in files:\n",
    "    lines_en = file[\"file_de\"].readlines() \n",
    "    lines_de = file[\"file_en\"].readlines()\n",
    "\n",
    "    # Remove stopwords\n",
    "    for i in range(len(lines_de)):\n",
    "        querywords = lines_en[i].split()\n",
    "        resultwords_en  = [word.lower() for word in querywords if word.lower() not in stop_words_en]\n",
    "        result_en = ' '.join(resultwords_en)\n",
    "        lines_en[i] = result_en\n",
    "\n",
    "        querywords = lines_de[i].split()\n",
    "        resultwords_de  = [word.lower() for word in querywords if word.lower() not in stop_words_de]\n",
    "        result_de = ' '.join(resultwords_de)\n",
    "        lines_de[i] = result_de\n",
    "\n",
    "    en_LASER_embeddings = []\n",
    "    de_LASER_embeddings = []\n",
    "\n",
    "    for i in range(len(lines_en)):\n",
    "        print(str(i) + \", \", end=\"\", flush=True)\n",
    "\n",
    "        a = np.array(get_vect(lines_de[i], lang = 'de'))\n",
    "        b = np.array(get_vect(lines_en[i], lang = 'en'))\n",
    "\n",
    "        de_LASER_embeddings.append(a)\n",
    "        en_LASER_embeddings.append(b)\n",
    "\n",
    "    # Save numpy arrays\n",
    "    path_de = 'de_' + file[\"name\"] + '.npy'\n",
    "    path_en = 'en_' + file[\"name\"] + '.npy'\n",
    "    \n",
    "    np.save(path_de, de_LASER_embeddings)\n",
    "    np.save(path_en, en_LASER_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting scores with a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024*2, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Embeddings to Tensors\n",
    "# Dataloaders\n",
    "embeddings_de = np.load('de_LASER_embeddings_0_to_1000.npy')\n",
    "embeddings_en = np.load('en_LASER_embeddings_0_to_1000.npy')\n",
    "\n",
    "embeddings_de_VAL = np.load('de_LASER_embeddings_VAL_ALL.npy')\n",
    "embeddings_en_VAL = np.load('en_LASER_embeddings_VAL_ALL.npy')\n",
    "\n",
    "embeddings = []\n",
    "embeddings_VAL = []\n",
    "\n",
    "for i in range(len(embeddings_de)):\n",
    "    embeddings.append(np.concatenate((embeddings_de[i], embeddings_en[i])))\n",
    "    \n",
    "for i in range(len(embeddings_de_VAL)):\n",
    "    embeddings_VAL.append(np.concatenate((embeddings_de_VAL[i][0], embeddings_en_VAL[i][0])))\n",
    "\n",
    "class LASER_Dataset(Dataset):\n",
    "    def __init__(self, embeddings, scores):\n",
    "        self.embeddings = torch.tensor(embeddings).float()\n",
    "        self.scores = torch.tensor(scores).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {'embedding': self.embeddings[item], 'score': self.scores[item]}\n",
    "\n",
    "# Load scores\n",
    "scores = [float(val) for val in de_train_scores]\n",
    "scores_VAL = [float(val) for val in de_train_scores_VAL]\n",
    "\n",
    "batch_size = 20\n",
    "dataset_train = LASER_Dataset(embeddings, scores)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_VAL = LASER_Dataset(embeddings_VAL, scores_VAL)\n",
    "dataloader_VAL = torch.utils.data.DataLoader(dataset_VAL, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_on_test():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(embeddings_VAL)):\n",
    "            emb = embeddings_VAL[i]\n",
    "            tens = torch.tensor(emb).float().to(device)\n",
    "            pred_score = model(tens)\n",
    "            \n",
    "            real_score = torch.tensor(scores_VAL[i]).float().view(1).to(device)\n",
    "            \n",
    "            loss = criterion(pred_score, real_score)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(embeddings_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "model = SimpleNet()\n",
    "model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    #print(\"Epoch \" + str(e))\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_loss_test = 0\n",
    "\n",
    "    for batch_idx, batch_samples in enumerate(dataloader_train):\n",
    "        model.train()  # put model to training mode\n",
    "        \n",
    "        emb, score = batch_samples['embedding'].to(device), batch_samples['score'].to(device)\n",
    "\n",
    "        pred_score = model(emb).view(-1)\n",
    "        # print(pred_score)\n",
    "        \n",
    "        loss = criterion(pred_score, score)\n",
    "        \n",
    "        # Zero out all of the gradients for the variables which the optimizer\n",
    "        # will update.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # This is the backwards pass: compute the gradient of the loss with\n",
    "        # respect to each  parameter of the model.\n",
    "        loss.backward()\n",
    "\n",
    "        # Actually update the parameters of the model using the gradients\n",
    "        # computed by the backwards pass.\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "    training_losses.append(total_epoch_loss)\n",
    "    test_loss = check_on_test()\n",
    "    test_losses.append(test_loss)\n",
    "    print(str(total_epoch_loss) + \" // \" + str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0031516516094057256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate\n",
    "predicted = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(embeddings_VAL)):\n",
    "        emb = embeddings_VAL[i]\n",
    "        tens = torch.tensor(emb).float().to(device)\n",
    "        pred_score = model(tens).item()\n",
    "        predicted.append(pred_score)\n",
    "\n",
    "\n",
    "pearson = pearsonr(predicted, scores_VAL[:len(embeddings_VAL)])[0]\n",
    "print(pearson)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(predicted, bins=50)\n",
    "plt.xlim([-7, 2])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(scores_VAL[:len(embeddings_VAL)], bins=100)\n",
    "plt.xlim([-7, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sci-kit Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a simple linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "X = embeddings\n",
    "y = scores[:len(embeddings)]\n",
    "\n",
    "reg.fit(X, y)\n",
    "\n",
    "pred = reg.predict(embeddings_VAL)\n",
    "\n",
    "actual = scores_VAL\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(actual, predicted)\n",
    "ax.set_xlim([-7, 3])\n",
    "ax.set_ylim([-7, 3])\n",
    "ax.set_xlabel('Real Age')\n",
    "ax.set_ylabel('Predicted Age')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dvMzrPlB15Q5"
   ],
   "machine_shape": "hm",
   "name": "NLP_CW_v7_GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
